#compdef skipfish
# egeektronic

local curcontext="$curcontext" state line

_arguments \
  '-h[guess what?]' \
  '-A[use specified HTTP authentication credentials]' \
  '-F[pretend that host resolves to IP]' \
  '-C[append a custom cookie to all requests]' \
  '-H[append a custom HTTP header to all requests]' \
  '-b[use headers consistent]:HEADER:->list-header' \
  '-N[do not accept any new cookies]' \
  '--auth-form[form authentication URL]:URLS:_urls' \
  '--auth-user[form authentication user]' \
  '--auth-pass[form authentication password]' \
  '--auth-verify-url[URL for in-session detection]' \
  '-d[maximum crawl tree depth]' \
  '-c[maximum children to index per node]' \
  '-x[maximum descendants to index per branch]' \
  '-r[max total number of requests to send]' \
  '-p[node and link crawl probability]' \
  '-q[repeat probabilistic scan with given seed]' \
  '-I[only follow URLs matching string]' \
  '-X[exclude URLs matching string]' \
  '-K[do not fuzz parameters named string]' \
  '-D[crawl cross-site links to another domain]' \
  '-B[trust, but do not crawl, another domain]' \
  '-Z[do not descend into 5xx locations]' \
  '-O[do not submit any forms]' \
  '-P[do not parse HTML, etc, to find new links]' \
  '-o[write output to specified directory]' \
  '-M[log warnings about mixed content / non-SSL passwords]' \
  '-E[log all HTTP/1.0 / HTTP/1.1 caching intent mismatches]' \
  '-U[log all external URLs and e-mails seen]' \
  '-Q[completely suppress duplicate nodes in reports]' \
  '-u[be quiet, disable realtime progress stats]' \
  '-v[enable runtime logging (to stderr)]' \
  '-W[use a specified read-write wordlist]' \
  '-S[load a supplemental read-only wordlist]' \
  '-L[do not auto-learn new keywords for the site]' \
  '-Y[do not fuzz extensions in directory brute-force]' \
  '-R[purge words hit more than age scans ago]' \
  '-T[add new form auto-fill rule]' \
  '-G[maximum number of keyword guesses to keep]' \
  '-z[load signatures from this file]' \
  '-g[max simultaneous TCP connections]' \
  '-m[max simultaneous connections]' \
  '-f[max number of consecutive HTTP errors]' \
  '-t[total request response timeout]' \
  '-w[individual network I/O timeout]' \
  '-i[timeout on idle HTTP connections]' \
  '-s[response size limit]' \
  '-e[do not keep binary responses for reporting]' \
  '-l[max requests per second]' \
  '-k[stop scanning after the given duration h:m:s]' \
  '--config[load the specified configuration file]' \

  case "$state" in
    list-header)
      _values -S : 'HEADER' 'i[MSIE]' 'f[Firefox]' 'i[iPhone]'
    ;;
  esac
